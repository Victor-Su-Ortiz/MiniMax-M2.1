{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MiniMax-M2.1 Parameter Tuning\n",
        "\n",
        "Experiment with different parameters to understand their effects on model output:\n",
        "- **Temperature**: Controls randomness (0-1)\n",
        "- **Top-p**: Nucleus sampling threshold\n",
        "- **Max tokens**: Output length limit\n",
        "- **System prompts**: Model behavior customization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup\n",
        "import sys\n",
        "sys.path.insert(0, '..')\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv('../.env')\n",
        "\n",
        "from src.minimax_client import MiniMaxClient\n",
        "\n",
        "client = MiniMaxClient()\n",
        "print(f\"Testing: {client.model}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Temperature Effects\n",
        "\n",
        "Temperature controls the randomness of outputs. Lower values produce more focused, deterministic responses.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare different temperatures\n",
        "prompt = \"Write a creative one-sentence story about a cat.\"\n",
        "temperatures = [0.1, 0.5, 0.9]\n",
        "\n",
        "print(\"Temperature Comparison\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Prompt: {prompt}\\n\")\n",
        "\n",
        "for temp in temperatures:\n",
        "    print(f\"Temperature: {temp}\")\n",
        "    print(\"-\" * 40)\n",
        "    # Run 3 times to show consistency/variation\n",
        "    for i in range(3):\n",
        "        response = client.simple_chat(prompt, temperature=temp, max_tokens=100)\n",
        "        print(f\"  Run {i+1}: {response}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Top-p (Nucleus Sampling)\n",
        "\n",
        "Top-p limits token selection to a cumulative probability. Lower values are more focused.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare different top_p values\n",
        "prompt = \"List 5 random animals.\"\n",
        "top_p_values = [0.1, 0.5, 0.95]\n",
        "\n",
        "print(\"Top-p Comparison\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Prompt: {prompt}\\n\")\n",
        "\n",
        "for top_p in top_p_values:\n",
        "    print(f\"Top-p: {top_p}\")\n",
        "    print(\"-\" * 40)\n",
        "    response = client.simple_chat(prompt, top_p=top_p, temperature=0.8)\n",
        "    print(f\"  {response}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Max Tokens\n",
        "\n",
        "Control the maximum length of generated responses.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare different max_tokens values\n",
        "prompt = \"Explain how computers work.\"\n",
        "max_tokens_values = [50, 150, 500]\n",
        "\n",
        "print(\"Max Tokens Comparison\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Prompt: {prompt}\\n\")\n",
        "\n",
        "for max_tokens in max_tokens_values:\n",
        "    print(f\"Max Tokens: {max_tokens}\")\n",
        "    print(\"-\" * 40)\n",
        "    response = client.simple_chat(prompt, max_tokens=max_tokens)\n",
        "    print(f\"  {response}\")\n",
        "    print(f\"  [Length: ~{len(response.split())} words]\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. System Prompt Engineering\n",
        "\n",
        "System prompts shape the model's behavior, personality, and response style.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Different personas with the same question\n",
        "question = \"What's the best way to learn programming?\"\n",
        "\n",
        "personas = [\n",
        "    {\n",
        "        \"name\": \"Concise Expert\",\n",
        "        \"prompt\": \"You are a concise technical expert. Give brief, direct answers without unnecessary explanation.\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Friendly Teacher\",\n",
        "        \"prompt\": \"You are a warm, encouraging teacher. Explain concepts in a friendly, approachable way with examples.\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Pirate\",\n",
        "        \"prompt\": \"You are a friendly pirate who speaks in pirate dialect. Answer questions helpfully but in character.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "print(\"System Prompt Comparison\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"Question: {question}\\n\")\n",
        "\n",
        "for persona in personas:\n",
        "    print(f\"Persona: {persona['name']}\")\n",
        "    print(\"-\" * 40)\n",
        "    response = client.simple_chat(question, system_prompt=persona['prompt'])\n",
        "    print(f\"{response}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Finding Optimal Settings\n",
        "\n",
        "Experiment with combining parameters for specific use cases.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Recommended settings for different use cases\n",
        "use_cases = {\n",
        "    \"Code Generation\": {\n",
        "        \"system_prompt\": \"You are an expert programmer. Write clean, efficient, well-documented code.\",\n",
        "        \"temperature\": 0.2,\n",
        "        \"top_p\": 0.9,\n",
        "        \"test_prompt\": \"Write a Python function to check if a string is a palindrome.\"\n",
        "    },\n",
        "    \"Creative Writing\": {\n",
        "        \"system_prompt\": \"You are a creative writer with a vivid imagination.\",\n",
        "        \"temperature\": 0.9,\n",
        "        \"top_p\": 0.95,\n",
        "        \"test_prompt\": \"Write the opening paragraph of a mystery novel.\"\n",
        "    },\n",
        "    \"Factual Q&A\": {\n",
        "        \"system_prompt\": \"You are a knowledgeable assistant. Provide accurate, factual information.\",\n",
        "        \"temperature\": 0.1,\n",
        "        \"top_p\": 0.8,\n",
        "        \"test_prompt\": \"What are the main causes of climate change?\"\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"Optimal Settings by Use Case\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for use_case, settings in use_cases.items():\n",
        "    print(f\"\\n{use_case}\")\n",
        "    print(f\"  Temperature: {settings['temperature']}, Top-p: {settings['top_p']}\")\n",
        "    print(\"-\" * 40)\n",
        "    \n",
        "    response = client.simple_chat(\n",
        "        settings['test_prompt'],\n",
        "        system_prompt=settings['system_prompt'],\n",
        "        temperature=settings['temperature'],\n",
        "        top_p=settings['top_p']\n",
        "    )\n",
        "    print(response)\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parameter Reference\n",
        "\n",
        "### General Guidelines\n",
        "\n",
        "- **Deterministic tasks** (code, facts): Low temperature (0.1-0.3), low top_p (0.8-0.9)\n",
        "- **Creative tasks** (stories, brainstorming): High temperature (0.7-0.9), high top_p (0.9-0.95)\n",
        "- **Balanced tasks** (explanations, Q&A): Medium temperature (0.4-0.6), medium top_p (0.85-0.9)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
