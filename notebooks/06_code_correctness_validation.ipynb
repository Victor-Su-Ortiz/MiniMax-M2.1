{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9bbcc7f",
   "metadata": {},
   "source": [
    "# Code Correctness Validation\n",
    "\n",
    "This notebook validates that generated code is syntactically correct and follows best practices.\n",
    "\n",
    "**Tests:**\n",
    "1. Python syntax validation via `ast.parse()`\n",
    "2. TypeScript syntax validation via `tsc` or heuristics\n",
    "3. JSON schema compliance\n",
    "4. Code complexity metrics (if radon installed)\n",
    "5. Multi-language generation test (Python, TypeScript, JSON, SQL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cf6be63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T22:02:10.372600Z",
     "iopub.status.busy": "2025-12-30T22:02:10.372332Z",
     "iopub.status.idle": "2025-12-30T22:02:10.671898Z",
     "shell.execute_reply": "2025-12-30T22:02:10.671594Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Setup complete | radon: True | pyflakes: True\n"
     ]
    }
   ],
   "source": [
    "# Setup and imports\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import ast\n",
    "import re\n",
    "import tempfile\n",
    "import subprocess\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from typing import Optional, Any\n",
    "from datetime import datetime\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('../.env')\n",
    "\n",
    "from src.minimax_client import MiniMaxClient\n",
    "\n",
    "# Optional: radon for complexity metrics\n",
    "try:\n",
    "    from radon.complexity import cc_visit\n",
    "    from radon.metrics import mi_visit\n",
    "    HAS_RADON = True\n",
    "except ImportError:\n",
    "    HAS_RADON = False\n",
    "    print(\"‚ö†Ô∏è radon not installed - pip install radon for complexity metrics\")\n",
    "\n",
    "# Optional: pyflakes for lint checking\n",
    "try:\n",
    "    from pyflakes import api as pyflakes_api\n",
    "    from pyflakes import reporter as pyflakes_reporter\n",
    "    HAS_PYFLAKES = True\n",
    "except ImportError:\n",
    "    HAS_PYFLAKES = False\n",
    "    print(\"‚ö†Ô∏è pyflakes not installed - pip install pyflakes for lint checking\")\n",
    "\n",
    "print(f\"‚úì Setup complete | radon: {HAS_RADON} | pyflakes: {HAS_PYFLAKES}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "024fd154",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T22:02:10.673267Z",
     "iopub.status.busy": "2025-12-30T22:02:10.673185Z",
     "iopub.status.idle": "2025-12-30T22:02:10.705243Z",
     "shell.execute_reply": "2025-12-30T22:02:10.704847Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Client initialized | Model: MiniMax-M2.1\n"
     ]
    }
   ],
   "source": [
    "# Data structures\n",
    "@dataclass\n",
    "class ValidationResult:\n",
    "    valid: bool\n",
    "    language: str\n",
    "    errors: list = field(default_factory=list)\n",
    "    warnings: list = field(default_factory=list)\n",
    "    metrics: dict = field(default_factory=dict)\n",
    "\n",
    "@dataclass \n",
    "class TestResult:\n",
    "    name: str\n",
    "    passed: bool\n",
    "    score: float\n",
    "    details: dict = field(default_factory=dict)\n",
    "    validation: Optional[ValidationResult] = None\n",
    "    completion_time: float = 0.0\n",
    "    tokens_used: int = 0\n",
    "\n",
    "@dataclass\n",
    "class BenchmarkResults:\n",
    "    notebook: str\n",
    "    timestamp: str\n",
    "    tests: list = field(default_factory=list)\n",
    "    \n",
    "    @property\n",
    "    def pass_rate(self) -> float:\n",
    "        return sum(1 for t in self.tests if t.passed) / len(self.tests) * 100 if self.tests else 0\n",
    "    \n",
    "    @property\n",
    "    def avg_score(self) -> float:\n",
    "        return sum(t.score for t in self.tests) / len(self.tests) if self.tests else 0\n",
    "\n",
    "# Initialize client\n",
    "client = MiniMaxClient()\n",
    "print(f\"‚úì Client initialized | Model: {client.model}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f96a0a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T22:02:10.706261Z",
     "iopub.status.busy": "2025-12-30T22:02:10.706185Z",
     "iopub.status.idle": "2025-12-30T22:02:10.711465Z",
     "shell.execute_reply": "2025-12-30T22:02:10.711075Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Validation functions defined\n"
     ]
    }
   ],
   "source": [
    "# Validation functions\n",
    "def extract_code(response: str, lang: str = None) -> str:\n",
    "    \"\"\"Extract code from model response.\"\"\"\n",
    "    response = re.sub(r'<think>.*?</think>', '', response, flags=re.DOTALL)\n",
    "    pattern = rf'```{lang}\\s*\\n(.*?)```' if lang else r'```(?:\\w+)?\\s*\\n(.*?)```'\n",
    "    matches = re.findall(pattern, response, re.DOTALL | re.IGNORECASE)\n",
    "    return matches[0].strip() if matches else response.strip()\n",
    "\n",
    "def validate_python(code: str) -> ValidationResult:\n",
    "    \"\"\"Validate Python syntax.\"\"\"\n",
    "    errors, warnings, metrics = [], [], {'lines': len(code.split('\\n')), 'chars': len(code)}\n",
    "    try:\n",
    "        ast.parse(code)\n",
    "        valid = True\n",
    "    except SyntaxError as e:\n",
    "        valid = False\n",
    "        errors.append(f\"Line {e.lineno}: {e.msg}\")\n",
    "    \n",
    "    if HAS_PYFLAKES and valid:\n",
    "        import io\n",
    "        w, e = io.StringIO(), io.StringIO()\n",
    "        pyflakes_api.check(code, '<gen>', pyflakes_reporter.Reporter(w, e))\n",
    "        if w.getvalue(): warnings.extend(w.getvalue().strip().split('\\n'))\n",
    "        if e.getvalue(): errors.extend(e.getvalue().strip().split('\\n'))\n",
    "    \n",
    "    if HAS_RADON and valid:\n",
    "        try:\n",
    "            cc = cc_visit(code)\n",
    "            if cc:\n",
    "                metrics['avg_complexity'] = round(sum(c.complexity for c in cc) / len(cc), 2)\n",
    "                metrics['max_complexity'] = max(c.complexity for c in cc)\n",
    "            metrics['maintainability'] = round(mi_visit(code, True), 2)\n",
    "        except: pass\n",
    "    \n",
    "    return ValidationResult(valid=valid, language='python', errors=errors, warnings=warnings, metrics=metrics)\n",
    "\n",
    "def validate_typescript(code: str) -> ValidationResult:\n",
    "    \"\"\"Validate TypeScript syntax.\"\"\"\n",
    "    errors, warnings, metrics = [], [], {'lines': len(code.split('\\n')), 'chars': len(code)}\n",
    "    \n",
    "    # Basic bracket balance check\n",
    "    valid = True\n",
    "    for open_b, close_b, name in [('{', '}', 'braces'), ('(', ')', 'parens'), ('[', ']', 'brackets')]:\n",
    "        diff = code.count(open_b) - code.count(close_b)\n",
    "        if diff != 0:\n",
    "            errors.append(f\"Unbalanced {name}: {diff:+d}\")\n",
    "            valid = False\n",
    "    \n",
    "    metrics['has_types'] = bool(re.search(r':\\s*(string|number|boolean|any|\\w+\\[\\])', code))\n",
    "    metrics['has_interfaces'] = 'interface ' in code\n",
    "    metrics['uses_any'] = bool(re.search(r':\\s*any\\b', code))\n",
    "    \n",
    "    return ValidationResult(valid=valid, language='typescript', errors=errors, warnings=warnings, metrics=metrics)\n",
    "\n",
    "def validate_json(code: str) -> ValidationResult:\n",
    "    \"\"\"Validate JSON syntax.\"\"\"\n",
    "    errors, metrics = [], {'chars': len(code)}\n",
    "    try:\n",
    "        parsed = json.loads(code)\n",
    "        valid = True\n",
    "        metrics['type'] = 'object' if isinstance(parsed, dict) else 'array' if isinstance(parsed, list) else type(parsed).__name__\n",
    "        metrics['size'] = len(parsed) if isinstance(parsed, (dict, list)) else 1\n",
    "    except json.JSONDecodeError as e:\n",
    "        valid = False\n",
    "        errors.append(f\"Line {e.lineno}: {e.msg}\")\n",
    "    return ValidationResult(valid=valid, language='json', errors=errors, metrics=metrics)\n",
    "\n",
    "def validate_sql(code: str) -> ValidationResult:\n",
    "    \"\"\"Validate SQL syntax.\"\"\"\n",
    "    errors, warnings, metrics = [], [], {'lines': len(code.split('\\n'))}\n",
    "    sql_kw = ['SELECT', 'INSERT', 'UPDATE', 'DELETE', 'CREATE', 'FROM', 'WHERE']\n",
    "    upper = code.upper()\n",
    "    \n",
    "    valid = any(kw in upper for kw in sql_kw)\n",
    "    if not valid: errors.append(\"No SQL keywords found\")\n",
    "    if code.count('(') != code.count(')'): \n",
    "        errors.append(\"Unbalanced parentheses\")\n",
    "        valid = False\n",
    "    if 'SELECT *' in upper: warnings.append(\"Uses SELECT *\")\n",
    "    \n",
    "    metrics['has_where'] = 'WHERE' in upper\n",
    "    metrics['has_join'] = 'JOIN' in upper\n",
    "    return ValidationResult(valid=valid, language='sql', errors=errors, warnings=warnings, metrics=metrics)\n",
    "\n",
    "print(\"‚úì Validation functions defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6e05408",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T22:02:10.712445Z",
     "iopub.status.busy": "2025-12-30T22:02:10.712362Z",
     "iopub.status.idle": "2025-12-30T22:02:10.715124Z",
     "shell.execute_reply": "2025-12-30T22:02:10.714808Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì 10 tests defined\n"
     ]
    }
   ],
   "source": [
    "# Test suite\n",
    "TESTS = [\n",
    "    {\"name\": \"Python - Binary Search\", \"lang\": \"python\", \"validator\": validate_python,\n",
    "     \"prompt\": \"Write a Python binary search function with type hints and docstring. Output ONLY code.\",\n",
    "     \"requirements\": [\"def \", \"return\"]},\n",
    "    {\"name\": \"Python - Async HTTP\", \"lang\": \"python\", \"validator\": validate_python,\n",
    "     \"prompt\": \"Write a Python async function using aiohttp to fetch a URL with error handling. Output ONLY code.\",\n",
    "     \"requirements\": [\"async def\", \"await\"]},\n",
    "    {\"name\": \"Python - Dataclass\", \"lang\": \"python\", \"validator\": validate_python,\n",
    "     \"prompt\": \"Write a Python dataclass User with id, name, email fields and an email validation method. Output ONLY code.\",\n",
    "     \"requirements\": [\"@dataclass\", \"class User\"]},\n",
    "    {\"name\": \"TypeScript - React Component\", \"lang\": \"typescript\", \"validator\": validate_typescript,\n",
    "     \"prompt\": \"Write a TypeScript React Button component with label, onClick, disabled props. Use proper types. Output ONLY code.\",\n",
    "     \"requirements\": [\"interface\", \"React\"]},\n",
    "    {\"name\": \"TypeScript - API Service\", \"lang\": \"typescript\", \"validator\": validate_typescript,\n",
    "     \"prompt\": \"Write a TypeScript ApiService class with get<T>, post<T>, delete methods using generics. Output ONLY code.\",\n",
    "     \"requirements\": [\"class\", \"async\", \"<T>\"]},\n",
    "    {\"name\": \"TypeScript - Custom Hook\", \"lang\": \"typescript\", \"validator\": validate_typescript,\n",
    "     \"prompt\": \"Write a TypeScript useLocalStorage hook that syncs state with localStorage. Output ONLY code.\",\n",
    "     \"requirements\": [\"useLocalStorage\", \"useState\"]},\n",
    "    {\"name\": \"JSON - User Profile\", \"lang\": \"json\", \"validator\": validate_json,\n",
    "     \"prompt\": \"Generate a JSON user profile with id, username, email, profile object (bio, avatar), created_at. Output ONLY JSON.\",\n",
    "     \"requirements\": [\"id\", \"username\", \"profile\"]},\n",
    "    {\"name\": \"JSON - Config File\", \"lang\": \"json\", \"validator\": validate_json,\n",
    "     \"prompt\": \"Generate a JSON config with database (host, port), cache (ttl), feature_flags array. Output ONLY JSON.\",\n",
    "     \"requirements\": [\"database\", \"cache\"]},\n",
    "    {\"name\": \"SQL - Top Customers\", \"lang\": \"sql\", \"validator\": validate_sql,\n",
    "     \"prompt\": \"Write SQL to find top 10 customers by order value with JOINs. Output ONLY SQL.\",\n",
    "     \"requirements\": [\"SELECT\", \"JOIN\", \"ORDER BY\"]},\n",
    "    {\"name\": \"SQL - Create Table\", \"lang\": \"sql\", \"validator\": validate_sql,\n",
    "     \"prompt\": \"Write SQL to create products table with id, name, price, category_id FK. Output ONLY SQL.\",\n",
    "     \"requirements\": [\"CREATE TABLE\", \"PRIMARY KEY\"]},\n",
    "]\n",
    "print(f\"‚úì {len(TESTS)} tests defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28e1f0aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T22:02:10.716051Z",
     "iopub.status.busy": "2025-12-30T22:02:10.715982Z",
     "iopub.status.idle": "2025-12-30T22:03:55.180834Z",
     "shell.execute_reply": "2025-12-30T22:03:55.179077Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Running Code Correctness Tests\n",
      "============================================================\n",
      "  Running: Python - Binary Search...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ‚úÖ Score: 100.0/100 | 4.8s\n",
      "  Running: Python - Async HTTP...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ‚úÖ Score: 100.0/100 | 5.0s\n",
      "  Running: Python - Dataclass...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ‚ùå Score: 50.0/100 | 21.4s\n",
      "  Running: TypeScript - React Component...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ‚úÖ Score: 100.0/100 | 10.9s\n",
      "  Running: TypeScript - API Service...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ‚úÖ Score: 100.0/100 | 21.6s\n",
      "  Running: TypeScript - Custom Hook...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ‚úÖ Score: 100.0/100 | 15.5s\n",
      "  Running: JSON - User Profile...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ‚úÖ Score: 100.0/100 | 3.7s\n",
      "  Running: JSON - Config File...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ‚úÖ Score: 100.0/100 | 3.4s\n",
      "  Running: SQL - Top Customers...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ‚úÖ Score: 100.0/100 | 4.6s\n",
      "  Running: SQL - Create Table...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ‚úÖ Score: 100.0/100 | 13.4s\n",
      "\n",
      "============================================================\n",
      "‚úÖ Completed 10 tests\n"
     ]
    }
   ],
   "source": [
    "# Test runner\n",
    "def run_test(test: dict) -> TestResult:\n",
    "    print(f\"  Running: {test['name']}...\")\n",
    "    try:\n",
    "        start = time.perf_counter()\n",
    "        response = client.chat([\n",
    "            {\"role\": \"system\", \"content\": f\"You are an expert {test['lang']} developer. Output ONLY code.\"},\n",
    "            {\"role\": \"user\", \"content\": test['prompt']}\n",
    "        ], max_tokens=2048, temperature=0.3)\n",
    "        elapsed = time.perf_counter() - start\n",
    "        \n",
    "        content = response.choices[0].message.content\n",
    "        code = extract_code(content, test['lang'])\n",
    "        validation = test['validator'](code)\n",
    "        \n",
    "        # Check requirements\n",
    "        req_met = sum(1 for r in test['requirements'] if r.lower() in code.lower())\n",
    "        req_score = req_met / len(test['requirements']) * 100\n",
    "        \n",
    "        # Score: 50% syntax, 50% requirements, penalty for errors\n",
    "        score = max(0, (100 if validation.valid else 0) * 0.5 + req_score * 0.5 - len(validation.errors) * 10)\n",
    "        passed = validation.valid and req_score >= 75\n",
    "        \n",
    "        return TestResult(name=test['name'], passed=passed, score=round(score, 1),\n",
    "            details={'req_met': f\"{req_met}/{len(test['requirements'])}\", 'errors': len(validation.errors)},\n",
    "            validation=validation, completion_time=elapsed, tokens_used=response.usage.completion_tokens)\n",
    "    except Exception as e:\n",
    "        return TestResult(name=test['name'], passed=False, score=0, details={'error': str(e)})\n",
    "\n",
    "# Run tests\n",
    "print(\"üöÄ Running Code Correctness Tests\")\n",
    "print(\"=\" * 60)\n",
    "results = BenchmarkResults(notebook=\"06_code_correctness\", timestamp=datetime.now().isoformat())\n",
    "\n",
    "for test in TESTS:\n",
    "    result = run_test(test)\n",
    "    results.tests.append(result)\n",
    "    status = \"‚úÖ\" if result.passed else \"‚ùå\"\n",
    "    print(f\"    {status} Score: {result.score}/100 | {result.completion_time:.1f}s\")\n",
    "\n",
    "print(f\"\\n{'='*60}\\n‚úÖ Completed {len(results.tests)} tests\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84824382",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T22:03:55.187838Z",
     "iopub.status.busy": "2025-12-30T22:03:55.187557Z",
     "iopub.status.idle": "2025-12-30T22:03:55.198119Z",
     "shell.execute_reply": "2025-12-30T22:03:55.197534Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## üìä Results Summary"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìà Overall Statistics:\n",
      "   Pass Rate: 9/10 (90.0%)\n",
      "   Syntax Valid: 10/10 (100.0%)\n",
      "   Average Score: 95.0/100\n",
      "   Total Time: 104.4s\n",
      "\n",
      "üìä By Language:\n",
      "   PYTHON       | 2/3 passed | Avg: 83\n",
      "   TYPESCRIPT   | 3/3 passed | Avg: 100\n",
      "   JSON         | 2/2 passed | Avg: 100\n",
      "   SQL          | 2/2 passed | Avg: 100\n",
      "\n",
      "Test                            Pass   Score    Errors \n",
      "-------------------------------------------------------\n",
      "Python - Binary Search           ‚úÖ      100      0    \n",
      "Python - Async HTTP              ‚úÖ      100      0    \n",
      "Python - Dataclass               ‚ùå       50      0    \n",
      "TypeScript - React Component     ‚úÖ      100      0    \n",
      "TypeScript - API Service         ‚úÖ      100      0    \n",
      "TypeScript - Custom Hook         ‚úÖ      100      0    \n",
      "JSON - User Profile              ‚úÖ      100      0    \n",
      "JSON - Config File               ‚úÖ      100      0    \n",
      "SQL - Top Customers              ‚úÖ      100      0    \n",
      "SQL - Create Table               ‚úÖ      100      0    \n"
     ]
    }
   ],
   "source": [
    "# Results summary\n",
    "display(Markdown(\"## üìä Results Summary\"))\n",
    "\n",
    "passed = sum(1 for t in results.tests if t.passed)\n",
    "total = len(results.tests)\n",
    "syntax_valid = sum(1 for t in results.tests if t.validation and t.validation.valid)\n",
    "\n",
    "print(f\"\\nüìà Overall Statistics:\")\n",
    "print(f\"   Pass Rate: {passed}/{total} ({results.pass_rate:.1f}%)\")\n",
    "print(f\"   Syntax Valid: {syntax_valid}/{total} ({syntax_valid/total*100:.1f}%)\")\n",
    "print(f\"   Average Score: {results.avg_score:.1f}/100\")\n",
    "print(f\"   Total Time: {sum(t.completion_time for t in results.tests):.1f}s\")\n",
    "\n",
    "# By language\n",
    "print(f\"\\nüìä By Language:\")\n",
    "langs = {}\n",
    "for t in results.tests:\n",
    "    lang = t.validation.language if t.validation else 'unknown'\n",
    "    if lang not in langs: langs[lang] = {'passed': 0, 'total': 0, 'scores': []}\n",
    "    langs[lang]['total'] += 1\n",
    "    langs[lang]['scores'].append(t.score)\n",
    "    if t.passed: langs[lang]['passed'] += 1\n",
    "\n",
    "for lang, s in langs.items():\n",
    "    print(f\"   {lang.upper():12} | {s['passed']}/{s['total']} passed | Avg: {sum(s['scores'])/len(s['scores']):.0f}\")\n",
    "\n",
    "# Detailed table\n",
    "print(f\"\\n{'Test':<30} {'Pass':^6} {'Score':^8} {'Errors':^8}\")\n",
    "print(\"-\" * 55)\n",
    "for t in results.tests:\n",
    "    print(f\"{t.name:<30} {'‚úÖ' if t.passed else '‚ùå':^6} {t.score:>5.0f}   {t.details.get('errors', 'N/A'):^8}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d3b5c21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-30T22:03:55.199855Z",
     "iopub.status.busy": "2025-12-30T22:03:55.199725Z",
     "iopub.status.idle": "2025-12-30T22:03:55.205703Z",
     "shell.execute_reply": "2025-12-30T22:03:55.205322Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Results saved to benchmark_results/06_code_correctness.json\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "## üìã Feedback Summary\n",
       "\n",
       "**Model**: MiniMax-M2.1 | **Date**: 2025-12-30\n",
       "\n",
       "| Metric | Value |\n",
       "|--------|-------|\n",
       "| Syntax Validity | 10/10 (100%) |\n",
       "| Pass Rate | 9/10 (90%) |\n",
       "| Average Score | 95/100 |\n",
       "\n",
       "**Observations**: Model generates syntactically valid code consistently.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save results\n",
    "os.makedirs(\"benchmark_results\", exist_ok=True)\n",
    "\n",
    "output = {\n",
    "    'notebook': results.notebook, 'timestamp': results.timestamp,\n",
    "    'summary': {'pass_rate': results.pass_rate, 'avg_score': results.avg_score,\n",
    "                'syntax_valid_rate': syntax_valid/total*100, 'total': total, 'passed': passed},\n",
    "    'by_language': {l: {'passed': s['passed'], 'total': s['total'], 'avg_score': sum(s['scores'])/len(s['scores'])} \n",
    "                   for l, s in langs.items()},\n",
    "    'tests': [{'name': t.name, 'passed': t.passed, 'score': t.score, 'details': t.details,\n",
    "               'validation': asdict(t.validation) if t.validation else None,\n",
    "               'time': t.completion_time, 'tokens': t.tokens_used} for t in results.tests]\n",
    "}\n",
    "\n",
    "with open(\"benchmark_results/06_code_correctness.json\", 'w') as f:\n",
    "    json.dump(output, f, indent=2, default=str)\n",
    "print(\"‚úÖ Results saved to benchmark_results/06_code_correctness.json\")\n",
    "\n",
    "# Summary for feedback\n",
    "display(Markdown(f\"\"\"\n",
    "## üìã Feedback Summary\n",
    "\n",
    "**Model**: {client.model} | **Date**: {results.timestamp[:10]}\n",
    "\n",
    "| Metric | Value |\n",
    "|--------|-------|\n",
    "| Syntax Validity | {syntax_valid}/{total} ({syntax_valid/total*100:.0f}%) |\n",
    "| Pass Rate | {passed}/{total} ({results.pass_rate:.0f}%) |\n",
    "| Average Score | {results.avg_score:.0f}/100 |\n",
    "\n",
    "**Observations**: Model {'generates syntactically valid code consistently' if syntax_valid/total > 0.8 else 'has some syntax issues'}.\n",
    "\"\"\"))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
